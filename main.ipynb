{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment prediciting based on tweeter's datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ALFA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ALFA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ALFA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# EDA tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing tools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "\n",
    "# training models tools\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('twitter_training.csv', encoding='ISO-8859-1')\n",
    "df_te = pd.read_csv('twitter_test.csv')\n",
    "df_val = pd.read_csv('twitter_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID       entity sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID     entity   sentiment  \\\n",
       "0      3364   Facebook  Irrelevant   \n",
       "1       352     Amazon     Neutral   \n",
       "2      8312  Microsoft    Negative   \n",
       "3      4371      CS-GO    Negative   \n",
       "4      4433     Google     Neutral   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  I mentioned on Facebook that I was struggling ...  \n",
       "1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2  @Microsoft Why do I pay for WORD when it funct...  \n",
       "3  CSGO matchmaking is so full of closet hacking,...  \n",
       "4  Now the President is slapping Americans in the...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5328</td>\n",
       "      <td>Hearthstone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@BlizzardCS what’s going on with Hearthstone f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7618</td>\n",
       "      <td>MaddenNFL</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@EAMaddenNFL is there a reason OFFLINE franchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7108</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson &amp; Johnson is about to enter phase 3 tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>PlayerUnknownsBattlegrounds(PUBG)</td>\n",
       "      <td>Negative</td>\n",
       "      <td>How is banning #PUBG going to fix anything? Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I played this interesting quiz on Amazon - Try...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID                             entity sentiment  \\\n",
       "0      5328                        Hearthstone  Negative   \n",
       "1      7618                          MaddenNFL  Negative   \n",
       "2      7108                    johnson&johnson  Negative   \n",
       "3     10008  PlayerUnknownsBattlegrounds(PUBG)  Negative   \n",
       "4        49                             Amazon   Neutral   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  @BlizzardCS what’s going on with Hearthstone f...  \n",
       "1  @EAMaddenNFL is there a reason OFFLINE franchi...  \n",
       "2  Johnson & Johnson is about to enter phase 3 tr...  \n",
       "3  How is banning #PUBG going to fix anything? Al...  \n",
       "4  I played this interesting quiz on Amazon - Try...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cont = df_tr['Tweet content'].to_numpy()\n",
    "te_cont = df_te['Tweet content'].to_numpy()\n",
    "val_cont = df_te['Tweet content'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specialChars(text):\n",
    "    \"\"\"This function removes all special characters from text.\"\"\"\n",
    "    temp = ''.join(letter for letter in text if letter.isalnum() or letter.isspace())\n",
    "    return ''.join(c for c in temp if ord(c) < 128 or c.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \"\"\"This function lemmatizes the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"This function converts all letters into lowercase and removes all English stop words from text.\"\"\"\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add('im') #customizing list of stop words\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>new_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>[get, borderlands, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>[come, border, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>[get, borderlands, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>[come, borderlands, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>[get, borderlands, 2, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>[realize, windows, partition, mac, like, 6, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>[realize, mac, window, partition, 6, years, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>[realize, windows, partition, mac, 6, years, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>[realize, windows, partition, mac, like, 6, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>[like, windows, partition, mac, like, 6, years...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID       entity sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "74681      9200       Nvidia  Positive   \n",
       "\n",
       "                                           Tweet content  \\\n",
       "0      im getting on borderlands and i will murder yo...   \n",
       "1      I am coming to the borders and I will kill you...   \n",
       "2      im getting on borderlands and i will kill you ...   \n",
       "3      im coming on borderlands and i will murder you...   \n",
       "4      im getting on borderlands 2 and i will murder ...   \n",
       "...                                                  ...   \n",
       "74677  Just realized that the Windows partition of my...   \n",
       "74678  Just realized that my Mac window partition is ...   \n",
       "74679  Just realized the windows partition of my Mac ...   \n",
       "74680  Just realized between the windows partition of...   \n",
       "74681  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                             new_content  \n",
       "0                             [get, borderlands, murder]  \n",
       "1                                   [come, border, kill]  \n",
       "2                               [get, borderlands, kill]  \n",
       "3                            [come, borderlands, murder]  \n",
       "4                          [get, borderlands, 2, murder]  \n",
       "...                                                  ...  \n",
       "74677  [realize, windows, partition, mac, like, 6, ye...  \n",
       "74678  [realize, mac, window, partition, 6, years, be...  \n",
       "74679  [realize, windows, partition, mac, 6, years, b...  \n",
       "74680  [realize, windows, partition, mac, like, 6, ye...  \n",
       "74681  [like, windows, partition, mac, like, 6, years...  \n",
       "\n",
       "[74682 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Firing functions into process our data and convert them into lemmatized words\n",
    "processed_content = []\n",
    "for text in tr_cont:\n",
    "    try:\n",
    "        new_text = remove_specialChars(text)\n",
    "        new_text = lemmatize_text(new_text)\n",
    "        new_text = remove_stopwords(new_text)\n",
    "        if new_text != '' and new_text != ' ':\n",
    "            processed_content.append(new_text)\n",
    "        else:\n",
    "            processed_content.append(np.nan)\n",
    "    except:\n",
    "        processed_content.append(np.nan)\n",
    "    \n",
    "df_tr['new_content'] = np.array(processed_content)\n",
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet ID         0\n",
       "entity           0\n",
       "sentiment        0\n",
       "Tweet content    0\n",
       "new_content      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.dropna(inplace=True)\n",
    "df_tr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>new_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "      <td>[mention, facebook, struggle, motivation, go, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "      <td>[bbc, news, amazon, boss, jeff, bezos, reject,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "      <td>[microsoft, pay, word, function, poorly, samsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "      <td>[csgo, matchmaking, full, closet, hack, truly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "      <td>[president, slap, americans, face, really, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8055</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>special shoutouts to microsoft excel 2013</td>\n",
       "      <td>[special, shoutouts, microsoft, excel, 2013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>6787</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Dumb Lucky☘️   (Fortnite Montage) youtu.be/psW...</td>\n",
       "      <td>[dumb, lucky, fortnite, montage, youtubepswjtn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3838</td>\n",
       "      <td>Cyberpunk2077</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Dang there goes my birthday present but maybe ...</td>\n",
       "      <td>[dang, go, birthday, present, maybe, better]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2008</td>\n",
       "      <td>CallOfDuty</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>It was ab fab seeing the 6 bungalows built in ...</td>\n",
       "      <td>[ab, fab, see, 6, bungalows, build, walsden, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4096</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.7 million viewers? wtf? and cs:go has more t...</td>\n",
       "      <td>[17, million, viewers, wtf, csgo, minecraft, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID         entity   sentiment  \\\n",
       "0        3364       Facebook  Irrelevant   \n",
       "1         352         Amazon     Neutral   \n",
       "2        8312      Microsoft    Negative   \n",
       "3        4371          CS-GO    Negative   \n",
       "4        4433         Google     Neutral   \n",
       "..        ...            ...         ...   \n",
       "495      8055      Microsoft    Positive   \n",
       "496      6787       Fortnite  Irrelevant   \n",
       "497      3838  Cyberpunk2077    Positive   \n",
       "498      2008     CallOfDuty  Irrelevant   \n",
       "499      4096          CS-GO     Neutral   \n",
       "\n",
       "                                         Tweet content  \\\n",
       "0    I mentioned on Facebook that I was struggling ...   \n",
       "1    BBC News - Amazon boss Jeff Bezos rejects clai...   \n",
       "2    @Microsoft Why do I pay for WORD when it funct...   \n",
       "3    CSGO matchmaking is so full of closet hacking,...   \n",
       "4    Now the President is slapping Americans in the...   \n",
       "..                                                 ...   \n",
       "495          special shoutouts to microsoft excel 2013   \n",
       "496  Dumb Lucky☘️   (Fortnite Montage) youtu.be/psW...   \n",
       "497  Dang there goes my birthday present but maybe ...   \n",
       "498  It was ab fab seeing the 6 bungalows built in ...   \n",
       "499  1.7 million viewers? wtf? and cs:go has more t...   \n",
       "\n",
       "                                           new_content  \n",
       "0    [mention, facebook, struggle, motivation, go, ...  \n",
       "1    [bbc, news, amazon, boss, jeff, bezos, reject,...  \n",
       "2    [microsoft, pay, word, function, poorly, samsu...  \n",
       "3    [csgo, matchmaking, full, closet, hack, truly,...  \n",
       "4    [president, slap, americans, face, really, com...  \n",
       "..                                                 ...  \n",
       "495       [special, shoutouts, microsoft, excel, 2013]  \n",
       "496  [dumb, lucky, fortnite, montage, youtubepswjtn...  \n",
       "497       [dang, go, birthday, present, maybe, better]  \n",
       "498  [ab, fab, see, 6, bungalows, build, walsden, l...  \n",
       "499  [17, million, viewers, wtf, csgo, minecraft, f...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Firing functions into process our data and convert them into lemmatized words\n",
    "processed_content = []\n",
    "for text in te_cont:\n",
    "    try:\n",
    "        new_text = remove_specialChars(text)\n",
    "        new_text = lemmatize_text(new_text)\n",
    "        new_text = remove_stopwords(new_text)\n",
    "        if new_text != '' and new_text != ' ':\n",
    "            processed_content.append(new_text)\n",
    "        else:\n",
    "            processed_content.append(np.nan)\n",
    "    except:\n",
    "        processed_content.append(np.nan)\n",
    "    \n",
    "df_te['new_content'] = np.array(processed_content)\n",
    "df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet ID         0\n",
       "entity           0\n",
       "sentiment        0\n",
       "Tweet content    0\n",
       "new_content      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing values\n",
    "df_te.dropna(inplace=True)\n",
    "df_te.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>new_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5328</td>\n",
       "      <td>Hearthstone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@BlizzardCS what’s going on with Hearthstone f...</td>\n",
       "      <td>[mention, facebook, struggle, motivation, go, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7618</td>\n",
       "      <td>MaddenNFL</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@EAMaddenNFL is there a reason OFFLINE franchi...</td>\n",
       "      <td>[bbc, news, amazon, boss, jeff, bezos, reject,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7108</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson &amp; Johnson is about to enter phase 3 tr...</td>\n",
       "      <td>[microsoft, pay, word, function, poorly, samsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>PlayerUnknownsBattlegrounds(PUBG)</td>\n",
       "      <td>Negative</td>\n",
       "      <td>How is banning #PUBG going to fix anything? Al...</td>\n",
       "      <td>[csgo, matchmaking, full, closet, hack, truly,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I played this interesting quiz on Amazon - Try...</td>\n",
       "      <td>[president, slap, americans, face, really, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4891</td>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "      <td>[special, shoutouts, microsoft, excel, 2013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4359</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "      <td>[dumb, lucky, fortnite, montage, youtubepswjtn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2652</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "      <td>[dang, go, birthday, present, maybe, better]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8069</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "      <td>[ab, fab, see, 6, bungalows, build, walsden, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6960</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "      <td>[17, million, viewers, wtf, csgo, minecraft, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID                             entity   sentiment  \\\n",
       "0        5328                        Hearthstone    Negative   \n",
       "1        7618                          MaddenNFL    Negative   \n",
       "2        7108                    johnson&johnson    Negative   \n",
       "3       10008  PlayerUnknownsBattlegrounds(PUBG)    Negative   \n",
       "4          49                             Amazon     Neutral   \n",
       "..        ...                                ...         ...   \n",
       "495      4891                GrandTheftAuto(GTA)  Irrelevant   \n",
       "496      4359                              CS-GO  Irrelevant   \n",
       "497      2652                        Borderlands    Positive   \n",
       "498      8069                          Microsoft    Positive   \n",
       "499      6960                    johnson&johnson     Neutral   \n",
       "\n",
       "                                         Tweet content  \\\n",
       "0    @BlizzardCS what’s going on with Hearthstone f...   \n",
       "1    @EAMaddenNFL is there a reason OFFLINE franchi...   \n",
       "2    Johnson & Johnson is about to enter phase 3 tr...   \n",
       "3    How is banning #PUBG going to fix anything? Al...   \n",
       "4    I played this interesting quiz on Amazon - Try...   \n",
       "..                                                 ...   \n",
       "495  ⭐️ Toronto is the arts and culture capital of ...   \n",
       "496  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...   \n",
       "497  Today sucked so it’s time to drink wine n play...   \n",
       "498  Bought a fraction of Microsoft today. Small wins.   \n",
       "499  Johnson & Johnson to stop selling talc baby po...   \n",
       "\n",
       "                                           new_content  \n",
       "0    [mention, facebook, struggle, motivation, go, ...  \n",
       "1    [bbc, news, amazon, boss, jeff, bezos, reject,...  \n",
       "2    [microsoft, pay, word, function, poorly, samsu...  \n",
       "3    [csgo, matchmaking, full, closet, hack, truly,...  \n",
       "4    [president, slap, americans, face, really, com...  \n",
       "..                                                 ...  \n",
       "495       [special, shoutouts, microsoft, excel, 2013]  \n",
       "496  [dumb, lucky, fortnite, montage, youtubepswjtn...  \n",
       "497       [dang, go, birthday, present, maybe, better]  \n",
       "498  [ab, fab, see, 6, bungalows, build, walsden, l...  \n",
       "499  [17, million, viewers, wtf, csgo, minecraft, f...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Firing functions into process our data and convert them into lemmatized words\n",
    "processed_content = []\n",
    "for text in te_cont:\n",
    "    try:\n",
    "        new_text = remove_specialChars(text)\n",
    "        new_text = lemmatize_text(new_text)\n",
    "        new_text = remove_stopwords(new_text)\n",
    "        if new_text != '' and new_text != ' ':\n",
    "            processed_content.append(new_text)\n",
    "        else:\n",
    "            processed_content.append(np.nan)\n",
    "    except:\n",
    "        processed_content.append(np.nan)\n",
    "    \n",
    "df_val['new_content'] = np.array(processed_content)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet ID         0\n",
       "entity           0\n",
       "sentiment        0\n",
       "Tweet content    0\n",
       "new_content      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing values\n",
    "df_val.dropna(inplace=True)\n",
    "df_val.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVec(dataframe):\n",
    "    \"\"\"This function uses word embedding (word2vec) to extract vectors from words\"\"\"\n",
    "    all_vectors = []\n",
    "    sentiment = []\n",
    "    index = -1\n",
    "    for tweet in dataframe['new_content']:\n",
    "        index+=1\n",
    "        vectors = []\n",
    "        array = []\n",
    "        array.append(tweet)\n",
    "        try:\n",
    "            model = Word2Vec(array, vector_size=100, window=5, min_count=1, sg=0)\n",
    "            senti = np.array(dataframe['sentiment'])[index]\n",
    "            sentiment.append(senti)\n",
    "        except:\n",
    "            continue\n",
    "        for word in tweet:\n",
    "            vector = model.wv[word]\n",
    "            vectors.append(np.array(vector).mean())                \n",
    "        # using mean of vectors of each tweet\n",
    "        all_vectors.append(vectors)\n",
    "    new_df = pd.DataFrame(all_vectors)\n",
    "    new_df['sentiment'] = sentiment\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = getVec(df_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = getVec(df_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = getVec(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>numeric_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3   4   5   6   7   8   9  ...  155  \\\n",
       "0 -0.000008  0.000681  0.000157       NaN NaN NaN NaN NaN NaN NaN  ...  NaN   \n",
       "1 -0.000008  0.000681  0.000157       NaN NaN NaN NaN NaN NaN NaN  ...  NaN   \n",
       "2 -0.000008  0.000681  0.000157       NaN NaN NaN NaN NaN NaN NaN  ...  NaN   \n",
       "3 -0.000008  0.000681  0.000157       NaN NaN NaN NaN NaN NaN NaN  ...  NaN   \n",
       "4  0.000655 -0.000008  0.000681  0.000157 NaN NaN NaN NaN NaN NaN  ...  NaN   \n",
       "\n",
       "   156  157  158  159  160  161  162  sentiment  numeric_sentiment  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN   Positive                  0  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN   Positive                  0  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN   Positive                  0  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN   Positive                  0  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN   Positive                  0  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert sentiment categories into numeric values for train dataset\n",
    "categories = new_df['sentiment'].unique()\n",
    "category_to_number = {category: number for number, category in enumerate(categories)}\n",
    "categories_list = new_df['sentiment'].to_numpy()\n",
    "numeric_values = [category_to_number[category] for category in categories_list]\n",
    "new_df['numeric_sentiment'] = numeric_values\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>numeric_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001100</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000004 -0.000008  0.000655 -0.000187 -0.000666 -0.000651 -0.000104   \n",
       "1  0.001100 -0.000123 -0.000273  0.000210  0.000464  0.000101 -0.000104   \n",
       "2 -0.000651 -0.000666 -0.000187  0.000655 -0.000008  0.000681  0.000157   \n",
       "3 -0.000104 -0.000651 -0.000666 -0.000187  0.000655 -0.000008  0.000681   \n",
       "4 -0.000273  0.000210  0.000464  0.000101 -0.000103 -0.000651 -0.000666   \n",
       "\n",
       "          7         8         9  ...  33  34  35  36  37  38  39  40  \\\n",
       "0  0.000101  0.000464  0.000681  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "1 -0.000651 -0.000666 -0.000187  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "2       NaN       NaN       NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "3  0.000157       NaN       NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "4 -0.000187  0.000655 -0.000008  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "    sentiment  numeric_sentiment  \n",
       "0  Irrelevant                  3  \n",
       "1     Neutral                  1  \n",
       "2    Negative                  2  \n",
       "3    Negative                  2  \n",
       "4     Neutral                  1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert sentiment categories into numeric values for test dataset\n",
    "categories = new_df1['sentiment'].unique()\n",
    "categories_list = new_df1['sentiment'].to_numpy()\n",
    "numeric_values = [category_to_number[category] for category in categories_list]\n",
    "new_df1['numeric_sentiment'] = numeric_values\n",
    "new_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>numeric_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001100</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000004 -0.000008  0.000655 -0.000187 -0.000666 -0.000651 -0.000104   \n",
       "1  0.001100 -0.000123 -0.000273  0.000210  0.000464  0.000101 -0.000104   \n",
       "2 -0.000651 -0.000666 -0.000187  0.000655 -0.000008  0.000681  0.000157   \n",
       "3 -0.000104 -0.000651 -0.000666 -0.000187  0.000655 -0.000008  0.000681   \n",
       "4 -0.000273  0.000210  0.000464  0.000101 -0.000103 -0.000651 -0.000666   \n",
       "\n",
       "          7         8         9  ...  33  34  35  36  37  38  39  40  \\\n",
       "0  0.000101  0.000464  0.000681  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "1 -0.000651 -0.000666 -0.000187  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "2       NaN       NaN       NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "3  0.000157       NaN       NaN  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "4 -0.000187  0.000655 -0.000008  ... NaN NaN NaN NaN NaN NaN NaN NaN   \n",
       "\n",
       "   sentiment  numeric_sentiment  \n",
       "0   Negative                  3  \n",
       "1   Negative                  1  \n",
       "2   Negative                  2  \n",
       "3   Negative                  2  \n",
       "4    Neutral                  1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert sentiment categories into numeric values for test dataset\n",
    "categories = new_df2['sentiment'].unique()\n",
    "categories_list = new_df1['sentiment'].to_numpy()\n",
    "numeric_values = [category_to_number[category] for category in categories_list]\n",
    "new_df2['numeric_sentiment'] = numeric_values\n",
    "new_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 0, 'Neutral': 1, 'Negative': 2, 'Irrelevant': 3}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_to_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NaN values with 0\n",
    "new_df.fillna(0, inplace=True)\n",
    "new_df1.fillna(0, inplace=True)\n",
    "new_df2.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting datasets\n",
    "X_train = new_df.drop(['sentiment', 'numeric_sentiment'], axis=1)\n",
    "y_train = new_df['numeric_sentiment']\n",
    "X_test = new_df1.drop(['sentiment', 'numeric_sentiment'], axis=1)\n",
    "y_test = new_df1['numeric_sentiment']\n",
    "X_val = new_df2.drop(['sentiment', 'numeric_sentiment'], axis=1)\n",
    "y_val = new_df2['numeric_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Zero padding\n",
    "diff = len(X_train.columns)-len(X_val.columns)\n",
    "for i in range(diff+1):\n",
    "    zPadd = np.zeros([len(X_test)])\n",
    "    X_test[40+i]=zPadd\n",
    "    X_val[40+i]=zPadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM:  0.530501002004008\n"
     ]
    }
   ],
   "source": [
    "# Train a SVM model\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test) #Evaluate SVM\n",
    "print(\"Accuracy of SVM: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GaussianNB(),\n",
       "                   param_distributions={'var_smoothing': [1e-09, 1e-08, 1e-07,\n",
       "                                                          1e-06, 1e-05]})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter distribution for random search for GaussianNB\n",
    "param_dist = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}\n",
    "\n",
    "# Perform random search\n",
    "clf_random_GNB = RandomizedSearchCV(GaussianNB(), param_distributions=param_dist, cv=5, n_iter=10)\n",
    "clf_random_GNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GNB:  0.473259104211305\n"
     ]
    }
   ],
   "source": [
    "# Evaluate GNB\n",
    "accuracy = clf_random_GNB.score(X_test, y_test)\n",
    "print(\"Accuracy of GNB: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true  y_pred\n",
       "0         3       3\n",
       "1         1       3\n",
       "2         2       1\n",
       "3         2       1\n",
       "4         1       3\n",
       "..      ...     ...\n",
       "494       0       0\n",
       "495       3       4\n",
       "496       0       0\n",
       "497       3       4\n",
       "498       1       1\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting target for X_val\n",
    "y_pred = clf.predict(X_val)\n",
    "pred_df = pd.DataFrame({'y_true': y_test, 'y_pred': y_pred}) #creating dataframe to compare real values with predicted values\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('y_val-vs-y_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* SVM is better because it works well when classes are well separated. On the other hand, GaussianNB assumes that the features are conditionally independent given the class, which may not be true in many real-world text classification problems\n",
    "\n",
    "* accuracy of SVM and the true values which were predicted were more than GNB so it predicted more than half of tweets' sentiments. However, there are some reasons which cause SVM predict better than GNB:\n",
    "* Complexity of Decision Boundary\n",
    "* Handling Non-Linearity\n",
    "* Robustness to Outliers\n",
    "* Parameter Sensitivity\n",
    "* Data Size\n",
    "* Imbalanced Datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
